# %%
from pymystem3 import Mystem
from nltk.corpus import stopwords 
from nltk.tokenize import word_tokenize 

# %%NLP Processing
from nltk.corpus import stopwords 
from nltk.tokenize import word_tokenize 
stop_words = set(stopwords.words('russian'))
sw1 = set(", . ' : ; ! ? â„– % * ( ) [ ] { | } # $ ^ & - + < = > ` ~ 1 2 3 4 5 6 7 8 9 0 | @ Â· \' - `")
sw2 = set("Â· â€¢ â€” â—ï¸ âœª \\ / ğŸ˜ ğŸ˜Š ğŸ˜‰ âˆ™ âœ” â–º â‚½ â€³ Â« Â» â€¦ âœ… â˜‘ï¸ ğŸ¤¦ â— ğŸ”° Â° ğŸ“Œ ğŸ“¢ â˜ â–¼ â¥ â˜› ã€‚ ğŸ” â¬‡ï¸ â–¶")
stop_words = stop_words.union(sw1)
stop_words = stop_words.union(sw2)
print(stop_words)

m = Mystem()

def remove_sw_lemma(data, stop_words=stop_words, ms=m):
  words = word_tokenize(data)
  wordsFiltered = ''
  for w in words:
    if w not in stop_words:
      wordsFiltered += w+' '
  return [x for x in ms.lemmatize(wordsFiltered) if x != ' ']

print(remove_sw_lemma('Ñ Ğ²Ğ°ÑÑ Ğ´ÑƒÑ€Ğ°Ğº Ğ¸ ĞºĞ°Ğº Ğ±Ñ‹ Ñ‚ÑƒÑ‚ ÑÑ‚Ğ° Ğ²ÑĞµ Ñ‚Ğ°ĞºĞ¾Ğµ â„–  % 0 7 %'))
